{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T16:15:33.594382Z",
     "start_time": "2025-12-12T16:15:22.803233Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install gymnasium",
   "id": "5af7e97f2885c841",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-1.2.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shivam mohite\\pycharmmiscproject\\.venv1\\lib\\site-packages (from gymnasium) (2.3.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\shivam mohite\\pycharmmiscproject\\.venv1\\lib\\site-packages (from gymnasium) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\shivam mohite\\pycharmmiscproject\\.venv1\\lib\\site-packages (from gymnasium) (4.15.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Downloading gymnasium-1.2.2-py3-none-any.whl (952 kB)\n",
      "   ---------------------------------------- 0.0/952.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 952.1/952.1 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium\n",
      "\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   -------------------- ------------------- 1/2 [gymnasium]\n",
      "   ---------------------------------------- 2/2 [gymnasium]\n",
      "\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-1.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T15:53:42.245604Z",
     "start_time": "2025-12-12T15:53:42.233785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Agent\n",
    "'''\n",
    "Agent is the learner or the decision maker.\n",
    "The concept of agent should be taken very broadly here, an agent can be Virtual Machine, Algorithm, An chatbot,....etc\n",
    "'''"
   ],
   "id": "2c244c9ef1c5a4d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAgent is the learner or the decision maker.\\nThe concept of agent should be taken very broadly here, an agent can be Virtual Machine, Algorithm, An chatbot,....etc\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T15:54:23.113990Z",
     "start_time": "2025-12-12T15:54:23.100279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reward\n",
    "'''\n",
    "A feedback signal telling the agent how good its action was.\n",
    "'''"
   ],
   "id": "66eb6820f761a08f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA feedback signal telling the agent how good its action was.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T15:55:52.513063Z",
     "start_time": "2025-12-12T15:55:52.502757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Penalty\n",
    "'''\n",
    "A feedback signal that signifies negative decision was made by agent and penalizies the agent\n",
    "'''"
   ],
   "id": "28355447800c51af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA feedback signal that signifies negative decision was made by agent and penalizies the agent\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T15:56:27.216940Z",
     "start_time": "2025-12-12T15:56:27.199053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Policy\n",
    "'''\n",
    "The strategy the agent uses to choose actions.\n",
    "'''"
   ],
   "id": "7efb940c8cf99560",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe strategy the agent uses to choose actions.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T15:57:05.600205Z",
     "start_time": "2025-12-12T15:57:05.587238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Environment\n",
    "'''\n",
    "It is basically everything the agent interacts with\n",
    "'''"
   ],
   "id": "6e4f3f2726ade9c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIt is basically everything the agent interacts with\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **THIS IS JUST A SIMPLE ENVIRONMENT WHICH AS SUCH HAS NO REAL PURPOSE, IT IS JUST A SIMPLE ENVIRONMENT WITH ONE CONSTANT OBSERVATION 0.5 AND NO ACTIONS OR PENALITIES**",
   "id": "c011c9e60fe95f85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T16:05:37.191706Z",
     "start_time": "2025-12-12T16:05:33.114610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "class SimpleEnvironment(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleEnvironment, self).__init__()\n",
    "\n",
    "        # Observation: just a single value\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
    "\n",
    "        # No actions\n",
    "        self.action_space = spaces.Discrete(1) # Dummy action\n",
    "\n",
    "    def reset(self):\n",
    "        return np.array([0.5], dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs = np.array([0.5], dtype=np.float32)\n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = {}\n",
    "        return obs, reward, done, info\n",
    "\n",
    "env = SimpleEnvironment()\n",
    "print(\"Reset :\",env.reset())"
   ],
   "id": "e42e3ca4352e8184",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset : [0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Running a simple 'CartPole-v1' Environment**",
   "id": "7dfa94a4f3ac793e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**we interact with the CartPole environment for 5 steps.\n",
    "At each step, we take a random action, and the environment returns:**\n",
    "1. the next state\n",
    "2. the reward (given by the environment, not manually assigned)\n",
    "3. whether the episode has ended\n",
    "Since CartPole gives a reward of 1 for every timestep the pole stays balanced, we receive a reward of 1 for each successful step."
   ],
   "id": "136ff4e651e1eb4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T16:17:17.556601Z",
     "start_time": "2025-12-12T16:17:17.536410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "state, info = env.reset()\n",
    "print(\"Initial State:\", state)\n",
    "\n",
    "for i in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    print(f\"Step {i+1}: State={next_state}, Reward={reward}\")\n",
    "\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "# Basically we are iterating the loop for 5 times performing random action in the environment and labeling it as reward for every action\n",
    "env.close()"
   ],
   "id": "de79ab14908b5477",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State: [-0.0315284  -0.04132834  0.04043938 -0.0364088 ]\n",
      "Step 1: State=[-0.03235496  0.15319107  0.03971121 -0.31606343], Reward=1.0\n",
      "Step 2: State=[-0.02929114 -0.04247336  0.03338994 -0.01112615], Reward=1.0\n",
      "Step 3: State=[-0.03014061 -0.23805787  0.03316741  0.2919019 ], Reward=1.0\n",
      "Step 4: State=[-0.03490177 -0.43363664  0.03900545  0.59485817], Reward=1.0\n",
      "Step 5: State=[-0.0435745  -0.6292822   0.05090262  0.89956796], Reward=1.0\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
